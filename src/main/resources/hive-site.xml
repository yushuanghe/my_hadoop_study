<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://shuanghe.com:3306/hive?createDatabaseIfNotExist=true</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
        <description>username to use against metastore database</description>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123456</value>
        <description>password to use against metastore database</description>
    </property>

    <property>
        <name>hive.metastore.uris</name>
        <value></value>
    </property>

    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>

    <property>
        <name>hive.server2.thrift.bind.host</name>
        <value>shuanghe.com</value>
    </property>

    <property>
        <name>hive.server2.thrift.client.user</name>
        <value>yushuanghe</value>
        <description>Username to use against thrift client</description>
    </property>

    <property>
        <name>hive.server2.thrift.client.password</name>
        <value>123456</value>
        <description>Password to use against thrift client</description>
    </property>

    <property>
        <name>hive.hwi.listen.port</name>
        <value>9999</value>
        <description>This is the port the Hive Web Interface will listen on</description>
    </property>

    <property>
        <name>hive.hwi.war.file</name>
        <value>lib/hive-hwi-1.2.2.jar</value>
    </property>

    <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>true</value>
    </property>

    <property>
        <name>datanucleus.fixedDatastore</name>
        <value>false</value>
    </property>

    <property>
        <name>hive.exec.local.scratchdir</name>
        <value>/home/yushuanghe/bigdata/hive</value>
        <description>Local scratch space for Hive jobs</description>
    </property>

    <property>
        <name>hive.downloaded.resources.dir</name>
        <value>/home/yushuanghe/bigdata/hive</value>
        <description>Temporary local directory for added resources in the remote file system.</description>
    </property>

    <property>
        <name>hive.querylog.location</name>
        <value>/home/yushuanghe/bigdata/hive</value>
        <description>Location of Hive run time structured log file</description>
    </property>

    <property>
        <name>hive.cli.print.header</name>
        <value>true</value>
        <description>Whether to print the names of the columns in query output.</description>
    </property>

    <property>
        <name>hive.cli.print.current.db</name>
        <value>true</value>
        <description>Whether to include the current database in the Hive prompt.</description>
    </property>

    <property>
        <name>hive.mapred.mode</name>
        <value>strict</value>
        <description>The mode in which the Hive operations are being performed.
            In strict mode, some risky queries are not allowed to run. They include:
            Cartesian Product.
            No partition being picked up for a query.
            Comparing bigints and strings.
            Comparing bigints and doubles.
            Orderby without limit.
        </description>
    </property>

    <property>
        <name>hive.enforce.bucketing</name>
        <value>true</value>
        <description>Whether bucketing is enforced. If true, while inserting into the table, bucketing is enforced.
        </description>
    </property>

    <property>
        <name>hive.fetch.task.conversion</name>
        <value>more</value>
        <description>
            Some select queries can be converted to single FETCH task minimizing latency.
            Currently the query should be single sourced not having any subquery and should not have
            any aggregations or distincts (which incurs RS), lateral views and joins.
            1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only
            2. more : SELECT, FILTER, LIMIT only (TABLESAMPLE, virtual columns)
        </description>
    </property>

</configuration>
